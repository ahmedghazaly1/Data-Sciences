# -*- coding: utf-8 -*-
"""DataScienceTask2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dYqbNPNwSeVkE-joz24gGpUqNM0izfta
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

df = pd.read_csv('/content/heart.csv')

print("Dataset Shape:", df.shape)
print("\nFirst 5 rows:")
display(df.head())

print("\nData Information:")
df.info()

print("\nSummary Statistics:")
display(df.describe())

print("\nMissing Values:")
print(df.isnull().sum())

categorical_cols = df.select_dtypes(include=['object']).columns
print("Categorical Columns:", categorical_cols)

le = LabelEncoder()
for col in categorical_cols:
    df[col] = le.fit_transform(df[col])

print("\nAfter Encoding:")
display(df.head())

X = df.drop('HeartDisease', axis=1)
y = df['HeartDisease']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("\nTraining set shape:", X_train.shape)
print("Testing set shape:", X_test.shape)


models = {
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "Naive Bayes": GaussianNB(),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM": SVC(kernel='linear', random_state=42)
}

results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    cm = confusion_matrix(y_test, y_pred)

    results[name] = {
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "confusion_matrix": cm
    }

    print(f"\n{name} Results:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print("Confusion Matrix:")
    print(cm)

model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    layers.Dropout(0.2),
    layers.Dense(32, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(X_train, y_train,
                    epochs=50,
                    batch_size=32,
                    validation_split=0.2,
                    verbose=1)

dl_loss, dl_accuracy = model.evaluate(X_test, y_test, verbose=0)
y_pred_dl = (model.predict(X_test) > 0.5).astype(int)
dl_precision = precision_score(y_test, y_pred_dl)
dl_recall = recall_score(y_test, y_pred_dl)
dl_cm = confusion_matrix(y_test, y_pred_dl)

results["Deep Learning"] = {
    "accuracy": dl_accuracy,
    "precision": dl_precision,
    "recall": dl_recall,
    "confusion_matrix": dl_cm
}

print("\nDeep Learning Results:")
print(f"Accuracy: {dl_accuracy:.4f}")
print(f"Precision: {dl_precision:.4f}")
print(f"Recall: {dl_recall:.4f}")
print("Confusion Matrix:")
print(dl_cm)

comparison_df = pd.DataFrame.from_dict({(i,j): results[i][j]
for i in results.keys()
for j in results[i].keys()},
orient='index')

print("\nModel Comparison:")
display(comparison_df)

plt.figure(figsize=(10, 6))
models_list = list(results.keys())
accuracy_values = [results[model]['accuracy'] for model in models_list]
plt.bar(models_list, accuracy_values)
plt.title('Model Accuracy Comparison')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.show()

fig, axes = plt.subplots(2, 3, figsize=(18, 10))
for i, (name, result) in enumerate(results.items()):
    ax = axes[i//3, i%3]
    sns.heatmap(result['confusion_matrix'], annot=True, fmt='d', ax=ax)
    ax.set_title(f'{name} Confusion Matrix')
plt.tight_layout()
plt.show()

best_model = max(results.items(), key=lambda x: x[1]['accuracy'])

print("\nBest Performing Model:")
print(f"Model: {best_model[0]}")
print(f"Accuracy: {best_model[1]['accuracy']:.4f}")
print(f"Precision: {best_model[1]['precision']:.4f}")
print(f"Recall: {best_model[1]['recall']:.4f}")

print("\nReasoning:")
print("The best model was selected based on the highest accuracy score. ")
print("Additional considerations include:")
print("- Balance between precision and recall")
print("- Computational efficiency")
print("- Interpretability of the model")

